{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Signal Classification Using Convolutional Neural Networks (CNNs)\n",
    "\n",
    "In this notebook, we'll classify urban sounds using Convolutional Neural Networks (CNNs) with TensorFlow. We will use the UrbanSound8K dataset, convert audio signals into spectrograms, and train a CNN model to classify these spectrograms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "First, we need to install the necessary libraries and import them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow numpy librosa matplotlib\n",
    "!pip install kaggle\n",
    "# Make sure to upload kaggle.json to Colab if using Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Ensure the dataset is available\n",
    "if not os.path.exists('UrbanSound8K.tar.gz'):\n",
    "    !kaggle datasets download -d chrisdonahue/urbansound8k\n",
    "    !tar -xzvf UrbanSound8K.tar.gz\n",
    "\n",
    "# Define the path to the dataset\n",
    "dataset_path = 'UrbanSound8K/audio/'\n",
    "classes = os.listdir(dataset_path)\n",
    "print('Classes:', classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preparation\n",
    "\n",
    "We need to load the audio files and convert them into spectrograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def audio_to_spectrogram(file_path, n_mels=128, fmax=8000):\n",
    "    y, sr = librosa.load(file_path, sr=None)\n",
    "    S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels, fmax=fmax)\n",
    "    return librosa.power_to_db(S, ref=np.max)\n",
    "\n",
    "# Collect data\n",
    "X = []\n",
    "y = []\n",
    "for label, class_name in enumerate(classes):\n",
    "    class_path = os.path.join(dataset_path, class_name)\n",
    "    for file_name in os.listdir(class_path):\n",
    "        if file_name.endswith('.wav'):\n",
    "            file_path = os.path.join(class_path, file_name)\n",
    "            spectrogram = audio_to_spectrogram(file_path)\n",
    "            X.append(spectrogram)\n",
    "            y.append(label)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Normalize data\n",
    "X = (X - np.min(X)) / (np.max(X) - np.min(X))\n",
    "X = np.expand_dims(X, axis=-1)  # Add channel dimension\n",
    "y = to_categorical(y, num_classes=len(classes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Building\n",
    "\n",
    "We'll build a CNN model to classify the spectrograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(X.shape[1], X.shape[2], 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(len(classes), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training\n",
    "\n",
    "We'll split the data into training and validation sets and then train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_val, y_val)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation\n",
    "\n",
    "Let's evaluate the model's performance on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(X_val, y_val)\n",
    "print(f'Validation Loss: {loss:.4f}')\n",
    "print(f'Validation Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

